{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahdi Ahmadi\n",
    "Blatt_1 Data Science\n",
    "teil 1 \n",
    "Schritt 1_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Dimension: 50 × 6\n",
      "    rank  x_class  region      start_datetime        max_datetime  \\\n",
      "0      1     X40+     486 2003-11-04 19:29:00 2003-11-04 19:53:00   \n",
      "1      2  X28.57+    9393 2001-04-02 21:32:00 2001-04-02 21:51:00   \n",
      "2      3  X24.57+     486 2003-10-28 09:51:00 2003-10-28 11:10:00   \n",
      "3      4  X24.42+     808 2005-09-07 17:17:00 2005-09-07 17:40:00   \n",
      "4      5  X20.67+    9415 2001-04-15 13:19:00 2001-04-15 13:50:00   \n",
      "5      6   X14.36     486 2003-10-29 20:37:00 2003-10-29 20:49:00   \n",
      "6      7   X13.37    2673 2017-09-06 11:53:00 2017-09-06 12:02:00   \n",
      "7      8   X12.97    8100 1997-11-06 11:49:00 1997-11-06 11:55:00   \n",
      "8      9   X12.95     930 2006-12-05 10:18:00 2006-12-05 10:35:00   \n",
      "9     10   X11.96     486 2003-11-02 17:03:00 2003-11-02 17:25:00   \n",
      "10    11   X11.88    2673 2017-09-10 15:35:00 2017-09-10 16:06:00   \n",
      "11    12   X10.18     720 2005-01-20 06:36:00 2005-01-20 07:01:00   \n",
      "12    13    X9.96    1263 2011-08-09 07:48:00 2011-08-09 08:05:00   \n",
      "13    14     X9.4     930 2006-12-06 18:29:00 2006-12-06 18:47:00   \n",
      "14    15       X9    3842 2024-10-03 12:08:00 2024-10-03 12:18:00   \n",
      "15    16     X8.9    9733 2001-12-13 14:20:00 2001-12-13 14:30:00   \n",
      "16    17    X8.87     808 2005-09-09 19:13:00 2005-09-09 20:04:00   \n",
      "17    18    X8.79    3664 2024-05-14 16:46:00 2024-05-14 16:51:00   \n",
      "18    19    X8.21    9077 2000-07-14 10:03:00 2000-07-14 10:24:00   \n",
      "19    20    X8.08    9415 2001-04-06 19:10:00 2001-04-06 19:21:00   \n",
      "20    21    X7.79    1429 2012-03-07 00:02:00 2012-03-07 00:24:00   \n",
      "21    22    X7.77     808 2005-09-08 20:52:00 2005-09-08 21:06:00   \n",
      "22    23    X7.77     486 2003-10-23 08:19:00 2003-10-23 08:35:00   \n",
      "23    24     X7.7    9591 2001-08-25 16:23:00 2001-08-25 16:45:00   \n",
      "24    25    X7.13    1990 2014-02-25 00:39:00 2014-02-25 00:49:00   \n",
      "25    26     X7.1    3842 2024-10-01 21:58:00 2024-10-01 22:20:00   \n",
      "26    27    X7.03    8307 1998-08-18 22:10:00 1998-08-18 22:19:00   \n",
      "27    28    X6.98      39 2002-07-23 00:18:00 2002-07-23 00:35:00   \n",
      "28    29    X6.37    3590 2024-02-22 22:08:00 2024-02-22 22:34:00   \n",
      "29    30    X5.89    3664 2024-05-11 01:10:00 2024-05-11 01:23:00   \n",
      "30    31    X5.83    9236 2000-11-26 16:34:00 2000-11-26 16:48:00   \n",
      "31    32    X5.61     488 2003-11-03 09:43:00 2003-11-03 09:55:00   \n",
      "32    33    X5.57    8307 1998-08-19 21:35:00 1998-08-19 21:45:00   \n",
      "33    34    X5.52     720 2005-01-17 06:59:00 2005-01-17 09:52:00   \n",
      "34    35    X5.37    8384 1998-11-22 06:30:00 1998-11-22 06:42:00   \n",
      "35    36    X5.24     649 2004-07-16 13:49:00 2004-07-16 13:55:00   \n",
      "36    37    X5.17     808 2005-09-09 09:42:00 2005-09-09 09:59:00   \n",
      "37    38    X5.17     365 2003-05-28 00:17:00 2003-05-28 00:27:00   \n",
      "38    39    X5.01    3536 2023-12-31 21:36:00 2023-12-31 21:55:00   \n",
      "39    40    X4.99    9767 2001-12-28 20:02:00 2001-12-28 20:45:00   \n",
      "40    41    X4.93    1890 2013-11-05 22:07:00 2013-11-05 22:12:00   \n",
      "41    42    X4.88     930 2006-12-13 02:14:00 2006-12-13 02:40:00   \n",
      "42    43    X4.77    8395 1998-11-28 04:54:00 1998-11-28 05:52:00   \n",
      "43    44    X4.74      39 2002-07-20 21:04:00 2002-07-20 21:30:00   \n",
      "44    45    X4.64    1748 2013-05-14 00:00:00 2013-05-14 01:11:00   \n",
      "45    46    X4.58    2192 2014-10-24 21:07:00 2014-10-24 21:41:00   \n",
      "46    47    X4.54    3825 2024-09-14 15:13:00 2024-09-14 15:29:00   \n",
      "47    48    X4.54      69 2002-08-24 00:49:00 2002-08-24 01:12:00   \n",
      "48    49    X4.52    3663 2024-05-06 05:38:00 2024-05-06 06:35:00   \n",
      "49    50    X4.39      30 2002-07-15 19:59:00 2002-07-15 20:08:00   \n",
      "\n",
      "          end_datetime  \n",
      "0  2003-11-04 20:06:00  \n",
      "1  2001-04-02 22:03:00  \n",
      "2  2003-10-28 11:24:00  \n",
      "3  2005-09-07 18:03:00  \n",
      "4  2001-04-15 13:55:00  \n",
      "5  2003-10-29 21:01:00  \n",
      "6  2017-09-06 12:10:00  \n",
      "7  1997-11-06 12:01:00  \n",
      "8  2006-12-05 10:45:00  \n",
      "9  2003-11-02 17:39:00  \n",
      "10 2017-09-10 16:31:00  \n",
      "11 2005-01-20 07:26:00  \n",
      "12 2011-08-09 08:08:00  \n",
      "13 2006-12-06 19:00:00  \n",
      "14 2024-10-03 12:27:00  \n",
      "15 2001-12-13 14:35:00  \n",
      "16 2005-09-09 20:36:00  \n",
      "17 2024-05-14 17:02:00  \n",
      "18 2000-07-14 10:43:00  \n",
      "19 2001-04-06 19:31:00  \n",
      "20 2012-03-07 00:40:00  \n",
      "21 2005-09-08 21:17:00  \n",
      "22 2003-10-23 08:49:00  \n",
      "23 2001-08-25 17:04:00  \n",
      "24 2014-02-25 01:03:00  \n",
      "25 2024-10-01 22:29:00  \n",
      "26 1998-08-18 22:28:00  \n",
      "27 2002-07-23 00:47:00  \n",
      "28 2024-02-22 22:43:00  \n",
      "29 2024-05-11 01:39:00  \n",
      "30 2000-11-26 16:56:00  \n",
      "31 2003-11-03 10:19:00  \n",
      "32 1998-08-19 21:50:00  \n",
      "33 2005-01-17 10:07:00  \n",
      "34 1998-11-22 06:49:00  \n",
      "35 2004-07-16 14:01:00  \n",
      "36 2005-09-09 10:08:00  \n",
      "37 2003-05-28 00:39:00  \n",
      "38 2023-12-31 22:08:00  \n",
      "39 2001-12-28 21:32:00  \n",
      "40 2013-11-05 22:15:00  \n",
      "41 2006-12-13 02:57:00  \n",
      "42 1998-11-28 06:13:00  \n",
      "43 2002-07-20 21:54:00  \n",
      "44 2013-05-14 01:20:00  \n",
      "45 2014-10-24 22:13:00  \n",
      "46 2024-09-14 15:47:00  \n",
      "47 2002-08-24 01:31:00  \n",
      "48 2024-05-06 06:47:00  \n",
      "49 2002-07-15 20:14:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_25360\\4122374591.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]#html datei einlesen\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://www.spaceweatherlive.com/en/solar-activity/top-50-solar-flares.html\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "response = requests.get(url,headers=headers)\n",
    "print(response)\n",
    "if response.status_code == 200:\n",
    "    page_content = response.text\n",
    "    soup = bs4.BeautifulSoup(page_content, 'html.parser')# html inhlat paresen\n",
    "\n",
    "    table = soup.find('table', {'class': 'table table-striped'})# tabllen als Variable speichern\n",
    "    if table:\n",
    "        df = pd.read_html(str(table))[0]#html datei einlesen\n",
    "        df.columns = ['rank', 'x_class', 'date', 'region', 'start_time', 'max_time', 'end_time', 'film'] # spalten benennen     \n",
    "        df = df.drop(columns = ['film'])\n",
    "        #kombi datum und zeit in 3 datetime spalten \n",
    "        for index, row in df.iterrows():\n",
    "            date_str = row ['date']\n",
    "            start_time_str = row ['start_time']\n",
    "            max_time_str = row ['max_time']\n",
    "            end_time_str = row ['end_time']\n",
    "\n",
    "            #kombinieren Datum und  Zeit\n",
    "            start_datetime = datetime.strptime(f\"{date_str} {start_time_str}\", \"%Y/%m/%d %H:%M\") \n",
    "            max_datetime = datetime.strptime(f\"{date_str} {max_time_str}\", \"%Y/%m/%d %H:%M\")\n",
    "            end_datetime = datetime.strptime(f\"{date_str} {end_time_str}\", \"%Y/%m/%d %H:%M\")\n",
    "\n",
    "            #aktualisieren der Daten\n",
    "            df.at[index, 'start_datetime'] = start_datetime\n",
    "            df.at[index, 'max_datetime'] = max_datetime\n",
    "            df.at[index, 'end_datetime'] = end_datetime\n",
    "            \n",
    "            # Lösche die alten Spalten\n",
    "        df_weather = df.drop(columns = ['date', 'start_time', 'max_time', 'end_time'])\n",
    "\n",
    "        #Regionen mit - = NaN\n",
    "        df_weather['region'] = df_weather['region'].replace('-', np.nan)\n",
    "        #Deimension des DataFrames\n",
    "        print(f\"Dimension: {df_weather.shape[0]} × {df_weather.shape[1]}\")\n",
    "\n",
    "        print(df_weather.head(50))\n",
    "    else:\n",
    "        print (\"Tablle nicht gefunden\")\n",
    "else :\n",
    "    print (\"Seite nicht gefunden\")\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teil 1 Schritt 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Dimension: 527 x 15\n",
      "     start_date start_time end_date end_time start_frequency end_frequency  \\\n",
      "0           (1)        (2)      (3)      (4)             (5)           (6)   \n",
      "1    1997/01/20      08:56    01/20    09:02           14000         12000   \n",
      "2    1997/04/01      14:00    04/01    14:15            8000          4000   \n",
      "3    1997/04/07      14:30    04/07    17:30           11000          1000   \n",
      "4    1997/05/12      05:15    05/14    16:00           12000            80   \n",
      "..          ...        ...      ...      ...             ...           ...   \n",
      "522  2023/05/05      08:04    05/05    08:50           14000          1300   \n",
      "523  2023/05/07      22:57    05/08    00:10           14000           600   \n",
      "524  2023/05/09      18:51    05/09    20:20           16000          1250   \n",
      "525  2023/06/17      10:37    06/17    10:42           14000          5500   \n",
      "526  2023/06/20      17:54    06/20    18:30           14000          2000   \n",
      "\n",
      "    solar_source_location noaa_active_region soft_xray_flare_importance  \\\n",
      "0                     (7)                (8)                        (9)   \n",
      "1                  ------              -----                       ----   \n",
      "2                  S25E16               8026                       M1.3   \n",
      "3                  S28E19               8027                       C6.8   \n",
      "4                  N21W08               8038                       C1.3   \n",
      "..                    ...                ...                        ...   \n",
      "522                N14E32              13296                       M2.1   \n",
      "523                N16W06              13296                       M1.6   \n",
      "524                N13W31              13296                       M4.2   \n",
      "525                S22E85                 EP                       ----   \n",
      "526                S17E73              13341                       X1.1   \n",
      "\n",
      "    cme_date cme_time central_position_angle cme_width cme_speed phtx_link  \n",
      "0       (10)     (11)                   (12)      (13)      (14)      (15)  \n",
      "1      01/20    09:31                    281        72       175      PHTX  \n",
      "2      04/01    15:18                     74        79       312      PHTX  \n",
      "3      04/07    14:27                   Halo       360       878      PHTX  \n",
      "4      05/12    05:30                   Halo       360       464      PHTX  \n",
      "..       ...      ...                    ...       ...       ...       ...  \n",
      "522    05/05    08:00                   Halo       360       770      PHTX  \n",
      "523    05/07    23:12                   Halo       360      1075      PHTX  \n",
      "524    05/09    19:00                   Halo       360      1209      PHTX  \n",
      "525    06/17    10:48                    113       154       570      PHTX  \n",
      "526    06/20    17:12                   Halo       360      1113      PHTX  \n",
      "\n",
      "[527 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# URL der Webseite\n",
    "url = \"https://cdaw.gsfc.nasa.gov/CME_list/radio/waves_type2.html\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extrahiere den Inhalt des <pre>-Tags\n",
    "    pre_tag = soup.find('pre')#tabelle faegt mit per tag an\n",
    "    \n",
    "    if pre_tag:\n",
    "        # Extrahiere den Text aus dem <pre>-Tag\n",
    "        pre_text = pre_tag.text\n",
    "\n",
    "        # Splitte den Text in Zeilen\n",
    "        lines = pre_text.split('\\n')\n",
    " \n",
    "        # Initialisiere eine leere Liste, um die Daten zu speichern\n",
    "        data = []\n",
    "        \n",
    "        # Überspringe die ersten Zeilen, die keine Daten enthalten\n",
    "        for line in lines[5:]:\n",
    "            if line.strip() == \"=================================================================================================\":\n",
    "                continue #strip entfernt leerzeichen\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "\n",
    "            # split String in einzelne Elemente,lerrzeichen als Trennzeichen\n",
    "            columns = line.split()\n",
    "            \n",
    "            # len = Anzahl der Elemente\n",
    "            if len(columns) == 15:\n",
    "                data.append(columns)#append elemente hinzufuegen\n",
    "        \n",
    "        columns = ['start_date', 'start_time', 'end_date', 'end_time', 'start_frequency', 'end_frequency',\n",
    "                   'solar_source_location', 'noaa_active_region', 'soft_xray_flare_importance', 'cme_date',\n",
    "                   'cme_time', 'central_position_angle', 'cme_width', 'cme_speed', 'phtx_link']\n",
    "        \n",
    "        # DataFrame data im Spalten zuordnen\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        \n",
    "        # Zeige die Dimensionen des DataFrames an\n",
    "        print(f\"Dimension: {df.shape[0]} x {df.shape[1]}\")#f string im {}zusammenfassen\n",
    "        # shape = dimensionen als tuple [0] = zeilen [1] = spalten\n",
    "        print(df)\n",
    "    else:\n",
    "        print(\"Pre-Tag nicht gefunden\")\n",
    "else:\n",
    "    print(\"Fehler beim Request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teil 1, Schritt 4\n",
    "Daten bereinigen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         start_datetime        end_datetime        cme_datetime  \\\n",
      "0                   NaT                 NaT                 NaT   \n",
      "1   1997-01-20 08:56:00 1997-01-20 09:02:00 1997-01-20 09:31:00   \n",
      "2   1997-04-01 14:00:00 1997-04-01 14:15:00 1997-04-01 15:18:00   \n",
      "3   1997-04-07 14:30:00 1997-04-07 17:30:00 1997-04-07 14:27:00   \n",
      "4   1997-05-12 05:15:00 1997-05-12 16:00:00 1997-05-12 05:30:00   \n",
      "..                  ...                 ...                 ...   \n",
      "522 2023-05-05 08:04:00 2023-05-05 08:50:00 1997-05-05 08:00:00   \n",
      "523 2023-05-07 22:57:00 2023-05-07 00:10:00 1997-05-07 23:12:00   \n",
      "524 2023-05-09 18:51:00 2023-05-09 20:20:00 1997-05-09 19:00:00   \n",
      "525 2023-06-17 10:37:00 2023-06-17 10:42:00 1997-06-17 10:48:00   \n",
      "526 2023-06-20 17:54:00 2023-06-20 18:30:00 1997-06-20 17:12:00   \n",
      "\n",
      "    start_frequency end_frequency solar_source_location noaa_active_region  \\\n",
      "0               (5)           (6)                   (7)                (8)   \n",
      "1             14000         12000                   NaN                NaN   \n",
      "2              8000          4000                S25E16               8026   \n",
      "3             11000          1000                S28E19               8027   \n",
      "4             12000            80                N21W08               8038   \n",
      "..              ...           ...                   ...                ...   \n",
      "522           14000          1300                N14E32              13296   \n",
      "523           14000           600                N16W06              13296   \n",
      "524           16000          1250                N13W31              13296   \n",
      "525           14000          5500                S22E85                 EP   \n",
      "526           14000          2000                S17E73              13341   \n",
      "\n",
      "    soft_xray_flare_importance central_position_angle cme_width cme_speed  \\\n",
      "0                          (9)                   (12)      (13)      (14)   \n",
      "1                          NaN                    281        72       175   \n",
      "2                         M1.3                     74        79       312   \n",
      "3                         C6.8                    NaN       360       878   \n",
      "4                         C1.3                    NaN       360       464   \n",
      "..                         ...                    ...       ...       ...   \n",
      "522                       M2.1                    NaN       360       770   \n",
      "523                       M1.6                    NaN       360      1075   \n",
      "524                       M4.2                    NaN       360      1209   \n",
      "525                        NaN                    113       154       570   \n",
      "526                       X1.1                    NaN       360      1113   \n",
      "\n",
      "    phtx_link  is_halo  width_lower_bound  \n",
      "0        (15)    False              False  \n",
      "1        PHTX    False              False  \n",
      "2        PHTX    False              False  \n",
      "3        PHTX    False              False  \n",
      "4        PHTX    False              False  \n",
      "..        ...      ...                ...  \n",
      "522      PHTX    False              False  \n",
      "523      PHTX    False              False  \n",
      "524      PHTX    False              False  \n",
      "525      PHTX    False              False  \n",
      "526      PHTX    False              False  \n",
      "\n",
      "[527 rows x 14 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_25360\\3312001739.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['start_datetime'] = pd.to_datetime(df['start_date'] + ' ' + df['start_time'], errors='coerce')#'coerce'= ungültige Werte in NaN\n",
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_25360\\3312001739.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['end_datetime'] = pd.to_datetime(df['start_date'] + ' ' + df['end_time'], errors='coerce')\n",
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_25360\\3312001739.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['cme_datetime'] = pd.to_datetime(df['cme_date'] + ' ' + df['cme_time'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "#--/-- = Platzhalter für fehlende datum und --:-- = Platzhalter für fehlende Zeit\n",
    "missing_values = [\"--\", \"----\", \"Halo\", \"------\", \"-----\", \"----\", \"--/--\", \"--:--\", \"----\", \"----\", \"----\"]\n",
    "df.replace(missing_values, np.nan, inplace=True)# inplace = true ersetzt im orginal daten;false = erstellt eine kopie\n",
    "\n",
    "#is_halo = neue Spalte; wenn central_position_angle = Halo dann True sonst False\n",
    "df['is_halo'] = df['central_position_angle'].apply(lambda x: True if x == \"Halo\" else False)\n",
    "df['central_position_angle'] = df['central_position_angle'].replace(\"Halo\", np.nan)#ersetzt Halo durch NaN\n",
    "\n",
    "#insistance(x = objrct , klasse)prüft ob x von klasse ist\n",
    "df['width_lower_bound'] = df['cme_width'].apply(lambda x: True if isinstance(x, str) and \">\" in x else False)\n",
    "df['cme_width'] = df['cme_width'].apply(lambda x: x.replace(\">\", \"\") if isinstance(x, str) else x)#entfernen > von String\n",
    "\n",
    "\n",
    "#to_datetime = konvert time,date in datetime\n",
    "df['start_datetime'] = pd.to_datetime(df['start_date'] + ' ' + df['start_time'], errors='coerce')#'coerce'= ungültige Werte in NaN \n",
    "df['end_datetime'] = pd.to_datetime(df['start_date'] + ' ' + df['end_time'], errors='coerce')\n",
    "\n",
    "#im df gabt keine jahr ,und error = coerce\n",
    "df['cme_date'] = '1997/' + df['cme_date']  \n",
    "\n",
    "df['cme_datetime'] = pd.to_datetime(df['cme_date'] + ' ' + df['cme_time'], errors='coerce')\n",
    "\n",
    "#drop = löschen von spalten\n",
    "df.drop(columns=['start_date', 'start_time', 'end_date', 'end_time', 'cme_date', 'cme_time'], inplace=True)\n",
    "\n",
    "#spalten am anfang vorrücken, col for col in df: eine for schleife die alle spalten durchgeht if col not in filtert die spalten\n",
    "cols = ['start_datetime', 'end_datetime', 'cme_datetime'] + [col for col in df if col not in ['start_datetime', 'end_datetime', 'cme_datetime']]\n",
    "df = df[cols]\n",
    "df_nasa = df\n",
    "\n",
    "        # Ergebnis anzeigen\n",
    "print(df_nasa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teil 2 Frage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         start_datetime        end_datetime        cme_datetime  \\\n",
      "225 2003-11-04 20:00:00                 NaT 1997-11-04 19:54:00   \n",
      "114 2001-04-02 22:05:00 2001-04-02 02:30:00 1997-04-02 22:06:00   \n",
      "218 2003-10-28 11:10:00                 NaT 1997-10-28 11:30:00   \n",
      "121 2001-04-15 14:05:00 2001-04-15 13:00:00 1997-04-15 14:06:00   \n",
      "219 2003-10-29 20:55:00                 NaT 1997-10-29 20:54:00   \n",
      "10  1997-11-06 12:20:00 1997-11-06 08:30:00 1997-11-06 12:10:00   \n",
      "471 2017-09-06 12:05:00 2017-09-06 08:00:00 1997-09-06 12:24:00   \n",
      "0                   NaT                 NaT                 NaT   \n",
      "222 2003-11-02 17:30:00 2003-11-02 01:00:00 1997-11-02 17:30:00   \n",
      "265 2005-01-20 07:15:00 2005-01-20 16:30:00 1997-01-20 06:54:00   \n",
      "327 2011-08-09 08:20:00 2011-08-09 08:35:00 1997-08-09 08:12:00   \n",
      "292 2005-09-09 19:45:00 2005-09-09 22:00:00 1997-09-09 19:48:00   \n",
      "81  2000-07-14 10:30:00 2000-07-14 14:30:00 1997-07-14 10:54:00   \n",
      "344 2012-03-07 01:00:00 2012-03-07 19:00:00 1997-03-07 00:24:00   \n",
      "130 2001-08-25 16:50:00 2001-08-25 23:00:00 1997-08-25 16:50:00   \n",
      "409 2014-02-25 00:56:00 2014-02-25 11:28:00 1997-02-25 01:25:00   \n",
      "182 2002-07-23 00:50:00 2002-07-23 04:00:00 1997-07-23 00:42:00   \n",
      "101 2000-11-26 17:00:00 2000-11-26 17:15:00 1997-11-26 17:06:00   \n",
      "224 2003-11-03 10:00:00 2003-11-03 12:30:00 1997-11-03 10:06:00   \n",
      "209 2003-05-28 01:00:00 2003-05-28 00:30:00 1997-05-28 00:50:00   \n",
      "152 2001-12-28 20:35:00 2001-12-28 03:00:00 1997-12-28 20:30:00   \n",
      "302 2006-12-13 02:45:00 2006-12-13 10:40:00 1997-12-13 02:54:00   \n",
      "181 2002-07-20 21:30:00 2002-07-20 22:20:00 1997-07-20 22:06:00   \n",
      "373 2013-05-14 01:16:00 2013-05-14 08:20:00 1997-05-14 01:25:00   \n",
      "189 2002-08-24 01:45:00 2002-08-24 03:25:00 1997-08-24 01:27:00   \n",
      "372 2013-05-13 16:15:00 2013-05-13 19:10:00 1997-05-13 16:07:00   \n",
      "20  1998-05-06 08:23:00 1998-05-06 08:35:00 1997-05-06 08:29:00   \n",
      "449 2015-05-05 22:24:00 2015-05-05 23:14:00 1997-05-05 22:24:00   \n",
      "223 2003-11-03 01:15:00 2003-11-03 01:25:00 1997-11-03 01:59:00   \n",
      "11  1997-11-27 13:30:00 1997-11-27 14:00:00 1997-11-27 13:56:00   \n",
      "262 2005-01-15 23:00:00 2005-01-15 00:00:00 1997-01-15 23:06:00   \n",
      "137 2001-09-24 10:45:00 2001-09-24 20:00:00 1997-09-24 10:30:00   \n",
      "255 2004-11-10 02:25:00 2004-11-10 03:40:00 1997-11-10 02:26:00   \n",
      "96  2000-11-24 15:25:00 2000-11-24 22:00:00 1997-11-24 15:30:00   \n",
      "118 2001-04-10 05:24:00                 NaT 1997-04-10 05:30:00   \n",
      "72  2000-06-06 15:20:00 2000-06-06 09:00:00 1997-06-06 15:54:00   \n",
      "313 2011-02-15 02:10:00 2011-02-15 07:00:00 1997-02-15 02:24:00   \n",
      "513 2023-02-17 20:30:00 2023-02-17 04:45:00 1997-02-17 20:12:00   \n",
      "515 2023-03-03 18:14:00 2023-03-03 19:32:00 1997-03-03 18:12:00   \n",
      "329 2011-09-06 22:30:00 2011-09-06 15:40:00 1997-09-06 23:05:00   \n",
      "293 2005-09-10 21:45:00 2005-09-10 01:00:00 1997-09-10 21:52:00   \n",
      "9   1997-11-04 06:00:00 1997-11-04 04:30:00 1997-11-04 06:10:00   \n",
      "389 2013-10-25 15:08:00 2013-10-25 22:32:00 1997-10-25 15:12:00   \n",
      "95  2000-11-24 05:10:00 2000-11-24 15:00:00 1997-11-24 05:30:00   \n",
      "120 2001-04-12 10:36:00 2001-04-12 10:40:00 1997-04-12 10:31:00   \n",
      "253 2004-11-07 16:25:00 2004-11-07 20:00:00 1997-11-07 16:54:00   \n",
      "263 2005-01-17 09:25:00 2005-01-17 16:00:00 1997-01-17 09:30:00   \n",
      "99  2000-11-25 19:00:00 2000-11-25 19:35:00 1997-11-25 19:31:00   \n",
      "178 2002-07-18 07:55:00 2002-07-18 08:45:00 1997-07-18 08:06:00   \n",
      "48  1999-10-14 09:10:00 1999-10-14 10:00:00 1997-10-14 09:26:00   \n",
      "\n",
      "    start_frequency end_frequency solar_source_location noaa_active_region  \\\n",
      "225           10000           200                S19W83              10486   \n",
      "114           14000           250                N19W72               9393   \n",
      "218           14000            40                S16E08              10486   \n",
      "121           14000            40                S20W85               9415   \n",
      "219           11000           500                S15W02              10486   \n",
      "10            14000           100                S18W63               8100   \n",
      "471           16000            70                S08W33              12673   \n",
      "0               (5)           (6)                   (7)                (8)   \n",
      "222           12000           250                S14W56              10486   \n",
      "265           14000            25                N14W61              10720   \n",
      "327           16000          4000                N17W69              11263   \n",
      "292           10000            50                S12E67              10808   \n",
      "81            14000            80                N22W07               9077   \n",
      "344           16000            30                N17E27              11429   \n",
      "130            8000           170                S17E34               9591   \n",
      "409           14000           100                S12E82              11990   \n",
      "182           11000           400                S13E72              10039   \n",
      "101           14000          7000                N18W38               9236   \n",
      "224            6000           400                N08W77              10488   \n",
      "209            1000           200                S07W20              10365   \n",
      "152           14000           350                S26E90               9756   \n",
      "302           12000           150                S06W23              10930   \n",
      "181           10000          2000                S13E90              10039   \n",
      "373           16000           240                N08E77              11748   \n",
      "189            5000           400                S02W81              10069   \n",
      "372           16000           300                N11E85              11748   \n",
      "20            14000          5000                S11W65               8210   \n",
      "449           14000           500                N15E79              12339   \n",
      "223            3000          1500                N10W83              10488   \n",
      "11            14000          7000                N17E63               8113   \n",
      "262            3000            40                N15W05              10720   \n",
      "137            7000            30                S16E23               9632   \n",
      "255           14000          1000                N09W49              10696   \n",
      "96            14000           200                N22W07               9236   \n",
      "118           14000           100                S23W09               9415   \n",
      "72            14000            40                N20E18               9026   \n",
      "313           16000           400                S20W12              11158   \n",
      "513           10000           180                N25E64              13229   \n",
      "515           14000          1100                N22W80              13234   \n",
      "329           16000           150                N14W18              11283   \n",
      "293           14000           200                S13E47              10808   \n",
      "9             14000           100                S14W33               8100   \n",
      "389           16000           200                S06E69              11882   \n",
      "95            14000           100                N20W05               9236   \n",
      "120           14000          7000                S19W43               9415   \n",
      "253           14000            60                N09W17              10696   \n",
      "263           14000            30                N15W25              10720   \n",
      "99             6000          2000                N20W23               9236   \n",
      "178           14000          1500                N19W30              10030   \n",
      "48            14000          4000                N11E32               8731   \n",
      "\n",
      "    soft_xray_flare_importance central_position_angle cme_width cme_speed  \\\n",
      "225                       X28.                    NaN       360      2657   \n",
      "114                       X20.                    261       244      2505   \n",
      "218                       X17.                    NaN       360      2459   \n",
      "121                       X14.                    245       167      1199   \n",
      "219                       X10.                    NaN       360      2029   \n",
      "10                        X9.4                    NaN       360      1556   \n",
      "471                       X9.3                    NaN       360      1571   \n",
      "0                          (9)                   (12)      (13)      (14)   \n",
      "222                       X8.3                    NaN       360      2598   \n",
      "265                       X7.1                    NaN       360       882   \n",
      "327                       X6.9                    NaN       360      1610   \n",
      "292                       X6.2                    NaN       360      2257   \n",
      "81                        X5.7                    NaN       360      1674   \n",
      "344                       X5.4                    NaN       360      2684   \n",
      "130                       X5.3                    NaN       360      1433   \n",
      "409                       X4.9                    NaN       360      2147   \n",
      "182                       X4.8                    NaN       360      2285   \n",
      "101                       X4.0                    NaN       360       980   \n",
      "224                       X3.9                    293       103      1420   \n",
      "209                       X3.6                    NaN       360      1366   \n",
      "152                       X3.4                    NaN       360      2216   \n",
      "302                       X3.4                    NaN       360      1774   \n",
      "181                       X3.3                    NaN       360      1941   \n",
      "373                       X3.2                    NaN       360      2625   \n",
      "189                       X3.1                    NaN       360      1913   \n",
      "372                       X2.8                    NaN       360      1850   \n",
      "20                        X2.7                    309       190      1099   \n",
      "449                       X2.7                    NaN       360       715   \n",
      "223                       X2.7                    304        65       827   \n",
      "11                        X2.6                     98        91       441   \n",
      "262                       X2.6                    NaN       360      2861   \n",
      "137                       X2.6                    NaN       360      2402   \n",
      "255                       X2.5                    NaN       360      3387   \n",
      "96                        X2.3                    NaN       360      1245   \n",
      "118                       X2.3                    NaN       360      2411   \n",
      "72                        X2.3                    NaN       360      1119   \n",
      "313                       X2.2                    NaN       360       669   \n",
      "513                       X2.2                    NaN       360      1315   \n",
      "515                       X2.1                    NaN       360       709   \n",
      "329                       X2.1                    NaN       360       575   \n",
      "293                       X2.1                    NaN       360      1893   \n",
      "9                         X2.1                    NaN       360       785   \n",
      "389                       X2.1                    NaN       360      1081   \n",
      "95                        X2.0                    NaN       360      1289   \n",
      "120                       X2.0                    NaN       360      1184   \n",
      "253                       X2.0                    NaN       360      1759   \n",
      "263                       X2.0                    NaN       360      2094   \n",
      "99                        X1.9                    NaN       360       671   \n",
      "178                       X1.8                    NaN       360      1099   \n",
      "48                        X1.8                    NaN       360      1250   \n",
      "\n",
      "    phtx_link  is_halo  width_lower_bound  soft_xray_flare_importance_numeric  \n",
      "225      PHTX    False              False                                28.0  \n",
      "114      PHTX    False              False                                20.0  \n",
      "218      PHTX    False              False                                17.0  \n",
      "121      PHTX    False              False                                14.0  \n",
      "219      PHTX    False              False                                10.0  \n",
      "10       PHTX    False              False                                 9.4  \n",
      "471      PHTX    False              False                                 9.3  \n",
      "0        (15)    False              False                                 9.0  \n",
      "222      PHTX    False              False                                 8.3  \n",
      "265      PHTX    False              False                                 7.1  \n",
      "327      PHTX    False              False                                 6.9  \n",
      "292      PHTX    False              False                                 6.2  \n",
      "81       PHTX    False              False                                 5.7  \n",
      "344      PHTX    False              False                                 5.4  \n",
      "130      PHTX    False              False                                 5.3  \n",
      "409      PHTX    False              False                                 4.9  \n",
      "182      PHTX    False              False                                 4.8  \n",
      "101      PHTX    False              False                                 4.0  \n",
      "224      PHTX    False              False                                 3.9  \n",
      "209      PHTX    False              False                                 3.6  \n",
      "152      PHTX    False              False                                 3.4  \n",
      "302      PHTX    False              False                                 3.4  \n",
      "181      PHTX    False              False                                 3.3  \n",
      "373      PHTX    False              False                                 3.2  \n",
      "189      PHTX    False              False                                 3.1  \n",
      "372      PHTX    False              False                                 2.8  \n",
      "20       PHTX    False              False                                 2.7  \n",
      "449      PHTX    False              False                                 2.7  \n",
      "223      PHTX    False              False                                 2.7  \n",
      "11       PHTX    False              False                                 2.6  \n",
      "262      PHTX    False              False                                 2.6  \n",
      "137      PHTX    False              False                                 2.6  \n",
      "255      PHTX    False              False                                 2.5  \n",
      "96       PHTX    False              False                                 2.3  \n",
      "118      PHTX    False              False                                 2.3  \n",
      "72       PHTX    False              False                                 2.3  \n",
      "313      PHTX    False              False                                 2.2  \n",
      "513      PHTX    False              False                                 2.2  \n",
      "515      PHTX    False              False                                 2.1  \n",
      "329      PHTX    False              False                                 2.1  \n",
      "293      PHTX    False              False                                 2.1  \n",
      "9        PHTX    False              False                                 2.1  \n",
      "389      PHTX    False              False                                 2.1  \n",
      "95       PHTX    False              False                                 2.0  \n",
      "120      PHTX    False              False                                 2.0  \n",
      "253      PHTX    False              False                                 2.0  \n",
      "263      PHTX    False              False                                 2.0  \n",
      "99       PHTX    False              False                                 1.9  \n",
      "178      PHTX    False              False                                 1.8  \n",
      "48       PHTX    False              False                                 1.8  \n",
      "Columns in df_spaceweather: Index(['rank', 'x_class', 'region', 'start_datetime', 'max_datetime',\n",
      "       'end_datetime'],\n",
      "      dtype='object')\n",
      "Columns in df_nasa: Index(['start_datetime', 'end_datetime', 'cme_datetime', 'start_frequency',\n",
      "       'end_frequency', 'solar_source_location', 'noaa_active_region',\n",
      "       'soft_xray_flare_importance', 'central_position_angle', 'cme_width',\n",
      "       'cme_speed', 'phtx_link', 'is_halo', 'width_lower_bound',\n",
      "       'soft_xray_flare_importance_numeric'],\n",
      "      dtype='object')\n",
      "Number of matches: 0\n",
      "Empty DataFrame\n",
      "Columns: [start_datetime, soft_xray_flare_importance]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_nasa is already defined DataFrame\n",
    "\n",
    "# Function to clean and convert soft_xray_flare_importance to numeric\n",
    "def clean_xray_importance(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove 'X' prefix and any non-numeric characters\n",
    "        value = value.strip('X').replace('(', '').replace(')', '')\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Apply the cleaning function to the column\n",
    "df_nasa['soft_xray_flare_importance_numeric'] = df_nasa['soft_xray_flare_importance'].apply(clean_xray_importance)\n",
    "\n",
    "# Drop rows where conversion failed (optional)\n",
    "df_nasa = df_nasa.dropna(subset=['soft_xray_flare_importance_numeric'])\n",
    "\n",
    "# Sort df_nasa by the numeric column in descending order\n",
    "df_nasa_sorted = df_nasa.sort_values(by='soft_xray_flare_importance_numeric', ascending=False)\n",
    "\n",
    "# Select the top 50 solar events\n",
    "df_top_50 = df_nasa_sorted.head(50)\n",
    "\n",
    "# Display the top 50 solar events\n",
    "print(df_top_50)\n",
    "\n",
    "# Drop the numeric column if no longer needed\n",
    "df_nasa_sorted = df_nasa_sorted.drop(columns=['soft_xray_flare_importance_numeric'])\n",
    "\n",
    "# Continue with the rest of the code\n",
    "df_spaceweather = df_weather\n",
    "\n",
    "# Check if both DataFrames are not empty\n",
    "if not df_spaceweather.empty and not df_nasa.empty:\n",
    "    # Print columns of both DataFrames to debug\n",
    "    print(\"Columns in df_spaceweather:\", df_spaceweather.columns)\n",
    "    print(\"Columns in df_nasa:\", df_nasa.columns)\n",
    "    \n",
    "    # Define the columns to compare\n",
    "    comparison_columns_nasa = ['start_datetime', 'soft_xray_flare_importance']\n",
    "    comparison_columns_spaceweather = ['start_datetime', 'x_class']\n",
    "\n",
    "    # Check if the required columns are present in both DataFrames\n",
    "    missing_columns_spaceweather = [col for col in comparison_columns_spaceweather if col not in df_spaceweather.columns]\n",
    "    missing_columns_nasa = [col for col in comparison_columns_nasa if col not in df_nasa.columns]\n",
    "\n",
    "    if missing_columns_spaceweather or missing_columns_nasa:\n",
    "        print(f\"Missing columns in df_spaceweather: {missing_columns_spaceweather}\")\n",
    "        print(f\"Missing columns in df_nasa: {missing_columns_nasa}\")\n",
    "    else:\n",
    "        # Rename columns in df_spaceweather to match df_nasa for comparison\n",
    "        df_spaceweather_renamed = df_spaceweather.rename(columns={'x_class': 'soft_xray_flare_importance'})\n",
    "\n",
    "        # Perform a merge to find matches based on comparison criteria\n",
    "        df_comparison = pd.merge(df_spaceweather_renamed[comparison_columns_nasa], df_nasa[comparison_columns_nasa], \n",
    "                                 on=comparison_columns_nasa, how='inner', suffixes=('_spaceweather', '_nasa'))\n",
    "\n",
    "        # Display the matches\n",
    "        print(f\"Number of matches: {df_comparison.shape[0]}\")\n",
    "        print(df_comparison)\n",
    "\n",
    "        # Save the matches to a file\n",
    "        df_comparison.to_csv('vergleich_spaceweather_nasa.csv', index=False)\n",
    "else:\n",
    "    print(\"Error: One or both DataFrames are empty. Please check the data loading process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "der Datum von Sonneneruption sind im beide daten äquvalent aber alles anderes sind nicht identisch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teil2 Frage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_25360\\4081312326.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nasa['start_datetime'] = pd.to_datetime(df_nasa['start_datetime'])\n",
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_25360\\4081312326.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nasa['year_month'] = df_nasa['start_datetime'].dt.to_period('M')\n",
      "C:\\Users\\mahdi\\AppData\\Local\\Temp\\ipykernel_25360\\4081312326.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nasa['soft_xray_flare_importance_numeric'] = df_nasa['soft_xray_flare_importance'].apply(clean_xray_importance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0                                                None\n",
      "1                                                None\n",
      "2                                                None\n",
      "3                                                None\n",
      "4                                                None\n",
      "5   start_datetime                        2003-10-...\n",
      "6   start_datetime                        2017-09-...\n",
      "7   start_datetime                        1997-11-...\n",
      "8   start_datetime                        2006-12-...\n",
      "9   start_datetime                        2003-11-...\n",
      "10  start_datetime                        2017-09-...\n",
      "11  start_datetime                        2005-01-...\n",
      "12  start_datetime                        2011-08-...\n",
      "13  start_datetime                        2006-12-...\n",
      "14                                               None\n",
      "15  start_datetime                        2001-12-...\n",
      "16  start_datetime                        2005-09-...\n",
      "17                                               None\n",
      "18  start_datetime                        2000-07-...\n",
      "19  start_datetime                        2001-04-...\n",
      "20  start_datetime                        2012-03-...\n",
      "21  start_datetime                        2005-09-...\n",
      "22  start_datetime                        2003-10-...\n",
      "23  start_datetime                        2001-08-...\n",
      "24  start_datetime                        2014-02-...\n",
      "25                                               None\n",
      "26                                               None\n",
      "27  start_datetime                        2002-07-...\n",
      "28                                               None\n",
      "29                                               None\n",
      "30  start_datetime                        2000-11-...\n",
      "31  start_datetime                        2003-11-...\n",
      "32                                               None\n",
      "33  start_datetime                        2005-01-...\n",
      "34                                               None\n",
      "35                                               None\n",
      "36  start_datetime                        2005-09-...\n",
      "37  start_datetime                        2003-05-...\n",
      "38                                               None\n",
      "39  start_datetime                        2001-12-...\n",
      "40  start_datetime                        2013-11-...\n",
      "41  start_datetime                        2006-12-...\n",
      "42                                               None\n",
      "43  start_datetime                        2002-07-...\n",
      "44  start_datetime                        2013-05-...\n",
      "45                                               None\n",
      "46                                               None\n",
      "47  start_datetime                        2002-08-...\n",
      "48                                               None\n",
      "49  start_datetime                        2002-07-...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_xray_importance(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip('X').replace('(', '').replace(')', '')\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def find_best_matches(df_nasa, df_spaceweather, top_n=50):\n",
    "    # Convert date columns to datetime\n",
    "    df_nasa['start_datetime'] = pd.to_datetime(df_nasa['start_datetime'])\n",
    "    df_spaceweather['start_datetime'] = pd.to_datetime(df_spaceweather['start_datetime'])\n",
    "    \n",
    "    # Extract year and month from the datetime columns\n",
    "    df_nasa['year_month'] = df_nasa['start_datetime'].dt.to_period('M')\n",
    "    df_spaceweather['year_month'] = df_spaceweather['start_datetime'].dt.to_period('M')\n",
    "    \n",
    "    # Convert x_class to numeric in df_spaceweather\n",
    "    df_spaceweather['x_class_numeric'] = df_spaceweather['x_class'].apply(clean_xray_importance)\n",
    "    \n",
    "    # Sort NASA data by soft_xray_flare_importance\n",
    "    df_nasa['soft_xray_flare_importance_numeric'] = df_nasa['soft_xray_flare_importance'].apply(clean_xray_importance)\n",
    "    df_nasa_sorted = df_nasa.sort_values(by='soft_xray_flare_importance_numeric', ascending=False)\n",
    "    \n",
    "    # Select top N solar events from SpaceWeatherLive data\n",
    "    df_spaceweather_top = df_spaceweather.head(top_n)\n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    for index, event in df_spaceweather_top.iterrows():\n",
    "        best_match = None\n",
    "        min_diff = float('inf')\n",
    "        \n",
    "        for _, nasa_event in df_nasa_sorted.iterrows():\n",
    "            if event['year_month'] == nasa_event['year_month']:\n",
    "                xray_diff = abs(event['x_class_numeric'] - nasa_event['soft_xray_flare_importance_numeric'])\n",
    "                \n",
    "                # Calculate a combined difference score\n",
    "                combined_diff = xray_diff\n",
    "                \n",
    "                if combined_diff < min_diff:\n",
    "                    min_diff = combined_diff\n",
    "                    best_match = nasa_event\n",
    "        \n",
    "        matches.append(best_match)\n",
    "    \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "# Beispielverwendung:\n",
    "# df_nasa = pd.read_csv('path_to_nasa_data.csv')\n",
    "# df_spaceweather = pd.read_csv('path_to_spaceweather_data.csv')\n",
    "\n",
    "# Aufruf der Funktion und Ausgabe der Ergebnisse\n",
    "best_matches = find_best_matches(df_nasa, df_spaceweather)\n",
    "print(best_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich verstehe die Frage nicht ganz, weil es gibt keine identische zeile einzieger gelichheit ist SatrtDatum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Beispiel-Daten erstellen\u001b[39;00m\n\u001b[0;32m      6\u001b[0m data_nasa \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1/1/2000\u001b[39m\u001b[38;5;124m'\u001b[39m, periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft_xray_flare_importance\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m)]\n\u001b[0;32m      9\u001b[0m }\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Beispiel-Daten erstellen\n",
    "data_nasa = {\n",
    "    'start_datetime': pd.date_range(start='1/1/2000', periods=200, freq='M'),\n",
    "    'soft_xray_flare_importance': ['X' + str(i % 10) for i in range(200)]\n",
    "}\n",
    "data_top_50 = {\n",
    "    'start_datetime': pd.date_range(start='1/1/2000', periods=50, freq='6M'),\n",
    "    'soft_xray_flare_importance': ['X' + str(i % 10) for i in range(50)]\n",
    "}\n",
    "\n",
    "df_nasa = pd.DataFrame(data_nasa)\n",
    "df_top_50 = pd.DataFrame(data_top_50)\n",
    "\n",
    "# Konvertieren der Datumswerte in das datetime-Format\n",
    "df_nasa['start_datetime'] = pd.to_datetime(df_nasa['start_datetime'])\n",
    "df_top_50['start_datetime'] = pd.to_datetime(df_top_50['start_datetime'])\n",
    "\n",
    "# Extrahieren von Jahr und Monat\n",
    "df_nasa['year_month'] = df_nasa['start_datetime'].dt.to_period('M')\n",
    "df_top_50['year_month'] = df_top_50['start_datetime'].dt.to_period('M')\n",
    "\n",
    "# Aggregieren der Anzahl der Flares pro Monat\n",
    "flare_counts = df_nasa.groupby('year_month').size()\n",
    "top_50_counts = df_top_50.groupby('year_month').size()\n",
    "\n",
    "# Erstellen der Grafik\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(flare_counts.index.to_timestamp(), flare_counts, label='Total Flares', color='blue')\n",
    "plt.scatter(top_50_counts.index.to_timestamp(), top_50_counts, color='red', label='Top 50 Flares', zorder=5)\n",
    "\n",
    "# Hinzufügen von Titeln und Labels\n",
    "plt.title('Anzahl der Flares pro Monat')\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Anzahl der Flares')\n",
    "plt.legend()\n",
    "\n",
    "# Anzeigen der Grafik\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
